{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk   # Importing NLP Tool Kit\n",
    "import string   #For getting punctuations from a string\n",
    "from nltk.corpus import stopwords  # For getting stopwords like 'the,in,been...'\n",
    "import re  # For Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = pd.read_csv('Tweet_Sentiment_Analysis_test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm wired I know I'm George I was made that way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service! Apple won't even talk to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                              tweet\n",
       "id                                                          \n",
       "1       0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
       "2       0  Finally a transparant silicon case ^^ Thanks t...\n",
       "3       0  We love this! Would you go? #talk #makememorie...\n",
       "4       0   I'm wired I know I'm George I was made that way \n",
       "5       1  What amazing service! Apple won't even talk to..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 666 entries, 1 to 666\n",
      "Data columns (total 2 columns):\n",
      "label    666 non-null int64\n",
      "tweet    666 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.6+ KB\n"
     ]
    }
   ],
   "source": [
    "tweet_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_strin = tweet_data.iloc[1]['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias… http://instagram.com/p/YGEt5JC6JM/ ther i'm at KJLSD twitter.com/34JKLIjklsd Asim\n"
     ]
    }
   ],
   "source": [
    "# first_strin_final = ''\n",
    "\n",
    "# for ch in first_strin:\n",
    "#     first_strin_final += ch\n",
    "    \n",
    "print(first_strin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias…  ther i'm at KJLSD  Asim\n"
     ]
    }
   ],
   "source": [
    "# Trying to remove urls from the string\n",
    "\n",
    "no_url_stringg = re.sub('http\\S+', \"\", first_strin)\n",
    "no_url_string2 = re.sub('twitter\\S+','',no_url_stringg)\n",
    "\n",
    "print(no_url_string2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_punctn = [char for char in no_url_string2 if char not in string.punctuation]\n",
    "\n",
    "# no_punctn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_punctn = ''.join(no_punctn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Punctuation string:\n",
      "\t Finally a transparant silicon case  Thanks to my uncle  yay Sony Xperia S sonyexperias…  ther im at KJLSD  Asim\n"
     ]
    }
   ],
   "source": [
    "print('No Punctuation string:\\n\\t',no_punctn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweet = [word for word in no_punctn.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Finally',\n",
       " 'transparant',\n",
       " 'silicon',\n",
       " 'case',\n",
       " 'Thanks',\n",
       " 'uncle',\n",
       " 'yay',\n",
       " 'Sony',\n",
       " 'Xperia',\n",
       " 'sonyexperias…',\n",
       " 'ther',\n",
       " 'im',\n",
       " 'KJLSD',\n",
       " 'Asim']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processor(tweet):\n",
    "    \"\"\"\n",
    "    Tokenization(Splitting a sentence into list of words) of the tweet\n",
    "      1. Removing URLs from the tweet\n",
    "      2. Removing Punctuations from the tweet\n",
    "      3. Removing stopwords (the,he,she,it)\n",
    "    \"\"\"\n",
    "    no_url_tweet = re.sub('http\\S+',\"\", tweet) #URL Removing\n",
    "    no_url_tweet2 = re.sub('twitter\\S+','', no_url_tweet)\n",
    "    no_punc_tweet = [char for char in no_url_tweet2 if char not in string.punctuation] #Removing Punctuations\n",
    "    #After removing Punctuations,no_punc_tweet is a list of characters...So we make it as words using .join()\n",
    "    #method and store that words list in no_punc_tweet\n",
    "    no_punc_tweet = ''.join(no_punc_tweet)\n",
    "    #Now we are using stopwords module from NLTK package to remove StopWords like (i,me,my,myself,we,our,etc...)\n",
    "    cleaned_tweet = [word for word in no_punc_tweet.split() if word.lower() not in stopwords.words('english')]\n",
    "    return cleaned_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the text_processor() method on all tweets...\n",
    "tweet_data['clean_tweet'] = tweet_data['tweet'].apply(text_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
       "      <td>[fingerprint, Pregnancy, Test, android, apps, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
       "      <td>[Finally, transparant, silicon, case, Thanks, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
       "      <td>[love, Would, go, talk, makememories, unplug, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm wired I know I'm George I was made that way</td>\n",
       "      <td>[Im, wired, know, Im, George, made, way]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service! Apple won't even talk to...</td>\n",
       "      <td>[amazing, service, Apple, wont, even, talk, qu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                              tweet  \\\n",
       "id                                                             \n",
       "1       0  #fingerprint #Pregnancy Test https://goo.gl/h1...   \n",
       "2       0  Finally a transparant silicon case ^^ Thanks t...   \n",
       "3       0  We love this! Would you go? #talk #makememorie...   \n",
       "4       0   I'm wired I know I'm George I was made that way    \n",
       "5       1  What amazing service! Apple won't even talk to...   \n",
       "\n",
       "                                          clean_tweet  \n",
       "id                                                     \n",
       "1   [fingerprint, Pregnancy, Test, android, apps, ...  \n",
       "2   [Finally, transparant, silicon, case, Thanks, ...  \n",
       "3   [love, Would, go, talk, makememories, unplug, ...  \n",
       "4            [Im, wired, know, Im, George, made, way]  \n",
       "5   [amazing, service, Apple, wont, even, talk, qu...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "\n",
      "Wait over.. Finally in hand iPhoneX #iPhoneX #iPhone10 #SpaceGray #256GB #Apple pic.twitter.com/OGO7gkeOpw \n",
      "\n",
      "['Wait', 'Finally', 'hand', 'iPhoneX', 'iPhoneX', 'iPhone10', 'SpaceGray', '256GB', 'Apple', 'pic'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tweet_data.iloc[123]:\n",
    "    print(i,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization - Making a list of words to a vector which Machine Learning Algorithm can understand\n",
    "\n",
    "    #1. Count no. of times a word occured in a tweet(Also Known As 'Term Frequency')\n",
    "    #2. Knowing how important the word is by using IDF(Inver Document Frequency)\n",
    "    #3. Normalize the vectors to unit length, to abstract from the original text length\n",
    "\n",
    "# We are using scikit-learn's CountVectorizer()\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_transformer = CountVectorizer(analyzer=text_processor).fit(tweet_data['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPad\n"
     ]
    }
   ],
   "source": [
    "print(bow_transformer.get_feature_names()[2220])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3816\n"
     ]
    }
   ],
   "source": [
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just received the #Samsung Note 2, many thanks to @COTTDS #phone http://instagr.am/p/RIQsBaBG_O/\n"
     ]
    }
   ],
   "source": [
    "tweet35 = tweet_data['tweet'][35]\n",
    "print(tweet35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow35 = bow_transformer.transform([tweet35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 30)\t1\n",
      "  (0, 243)\t1\n",
      "  (0, 766)\t1\n",
      "  (0, 920)\t1\n",
      "  (0, 2569)\t1\n",
      "  (0, 2850)\t1\n",
      "  (0, 3005)\t1\n",
      "  (0, 3431)\t1\n"
     ]
    }
   ],
   "source": [
    "print(bow35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0,22040):\n",
    "#     print('{} - {}'.format(i,bow_transformer.get_feature_names()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_bow = bow_transformer.transform(tweet_data['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:\n",
      " (666, 3816)\n"
     ]
    }
   ],
   "source": [
    "# Printing the Shape of the tweets_bow\n",
    "print('Shape:\\n',tweets_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7766"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_bow.nnz #Getting amount of non zero occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF  from scikit-learn\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit(tweets_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'tweet', 'clean_tweet'], dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3431)\t0.3194988632266593\n",
      "  (0, 3005)\t0.43358384057701904\n",
      "  (0, 2850)\t0.2072075830303434\n",
      "  (0, 2569)\t0.4077670507292109\n",
      "  (0, 920)\t0.24283946085098762\n",
      "  (0, 766)\t0.38944974682574335\n",
      "  (0, 243)\t0.43358384057701904\n",
      "  (0, 30)\t0.3194988632266593\n"
     ]
    }
   ],
   "source": [
    "tfidf35 = tfidf_transformer.transform(bow35)\n",
    "print(tfidf35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'received'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_transformer.get_feature_names()[3005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_tfidf = tfidf_transformer.transform(tweets_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we use Naive bayes Algorithm to classify\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_model = MultinomialNB().fit(tweets_tfidf, tweet_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: 0\n",
      "expected: 1\n"
     ]
    }
   ],
   "source": [
    "# print('Predicted:',pos_neg_model.predict(tfidf124)['label'])\n",
    "print('predicted:', pos_neg_model.predict(tfidf35)[0])\n",
    "print('expected:', tweet_data.label[147])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred = pos_neg_model.predict(tweets_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_train, tweet_test, label_train, label_test = train_test_split(tweet_data['tweet'], tweet_data['label'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('bow', CountVectorizer(analyzer=<function text_processor at 0x7f9b2ed9da60>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=...f=False, use_idf=True)), ('Classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_processor)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline.fit(tweet_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_pred = pipeline.predict(tweet_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.87       151\n",
      "           1       1.00      0.04      0.08        49\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       200\n",
      "   macro avg       0.88      0.52      0.47       200\n",
      "weighted avg       0.82      0.77      0.67       200\n",
      "\n",
      "Accuracy Score:\n",
      "\t 0.765\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(label_test, pipeline_pred))\n",
    "print('Accuracy Score:\\n\\t', accuracy_score(label_test, pipeline_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
